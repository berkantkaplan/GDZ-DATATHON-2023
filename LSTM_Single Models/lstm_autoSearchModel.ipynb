{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tarih</th>\n",
       "      <th>Dağıtılan Enerji (MWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>1593.944216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>1513.933887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>1402.612637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>1278.527266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>1220.697701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tarih  Dağıtılan Enerji (MWh)\n",
       "0  2018-01-01 00:00:00             1593.944216\n",
       "1  2018-01-01 01:00:00             1513.933887\n",
       "2  2018-01-01 02:00:00             1402.612637\n",
       "3  2018-01-01 03:00:00             1278.527266\n",
       "4  2018-01-01 04:00:00             1220.697701"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tarih</th>\n",
       "      <th>Dağıtılan Enerji (MWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-01 01:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-01 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-01 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-01 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tarih  Dağıtılan Enerji (MWh)\n",
       "0  2022-08-01 00:00:00                     NaN\n",
       "1  2022-08-01 01:00:00                     NaN\n",
       "2  2022-08-01 02:00:00                     NaN\n",
       "3  2022-08-01 03:00:00                     NaN\n",
       "4  2022-08-01 04:00:00                     NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_data = pd.read_csv(\"future.csv\").drop('Unnamed: 0' , axis = 1)\n",
    "future_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40152, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40152 entries, 0 to 40151\n",
      "Data columns (total 2 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Tarih                   40152 non-null  object \n",
      " 1   Dağıtılan Enerji (MWh)  40152 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 627.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 40152 entries, 2018-01-01 00:00:00 to 2022-07-31 23:00:00\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Dağıtılan Enerji (MWh)  40152 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 627.4 KB\n"
     ]
    }
   ],
   "source": [
    "data['Tarih'] = pd.to_datetime(data['Tarih'])\n",
    "future_data['Tarih'] = pd.to_datetime(future_data['Tarih'])\n",
    "data.set_index('Tarih', inplace=True)\n",
    "future_data.set_index('Tarih' , inplace=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dağıtılan Enerji (MWh)</th>\n",
       "      <td>40152.0</td>\n",
       "      <td>1836.805287</td>\n",
       "      <td>426.066085</td>\n",
       "      <td>870.18328</td>\n",
       "      <td>1499.165048</td>\n",
       "      <td>1813.409221</td>\n",
       "      <td>2129.407998</td>\n",
       "      <td>3633.105297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count         mean         std        min  \\\n",
       "Dağıtılan Enerji (MWh)  40152.0  1836.805287  426.066085  870.18328   \n",
       "\n",
       "                                25%          50%          75%          max  \n",
       "Dağıtılan Enerji (MWh)  1499.165048  1813.409221  2129.407998  3633.105297  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train | Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Seed ayarlamak\n",
    "seed_value = 34\n",
    "tf.keras.utils.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_temp = data.loc[data.index > '2022-07-23 23:00:00'].copy()\n",
    "X_train_temp = data.loc[data.index <= '2022-07-23 23:00:00'].copy()\n",
    "\n",
    "X_val_temp = X_train_temp[-96:]\n",
    "X_train_temp = X_train_temp[:-96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train max : Dağıtılan Enerji (MWh)    3633.105297\n",
      "dtype: float64\n",
      "X_val max : Dağıtılan Enerji (MWh)    2812.085678\n",
      "dtype: float64\n",
      "X_test max : Dağıtılan Enerji (MWh)    3079.546897\n",
      "dtype: float64\n",
      "X_train min : Dağıtılan Enerji (MWh)    870.18328\n",
      "dtype: float64\n",
      "X_val min : Dağıtılan Enerji (MWh)    1596.356554\n",
      "dtype: float64\n",
      "X_test min : Dağıtılan Enerji (MWh)    1594.214702\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train max : {X_train_temp.max()}\")\n",
    "print(f\"X_val max : {X_val_temp.max()}\")\n",
    "print(f\"X_test max : {X_test_temp.max()}\")\n",
    "\n",
    "print(f\"X_train min : {X_train_temp.min()}\")\n",
    "print(f\"X_val min : {X_val_temp.min()}\")\n",
    "print(f\"X_test min : {X_test_temp.min()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "train_scaled = scaler.transform(X_train_temp)\n",
    "test_scaled = scaler.transform(X_test_temp)\n",
    "\n",
    "val_scaled = scaler.transform(X_val_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# train_scaled = scaler.fit_transform(X_train_temp)\n",
    "# test_scaled = scaler.transform(X_test_temp)\n",
    "\n",
    "# val_scaled = scaler.transform(X_val_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buraya dikkat !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def packager(train_scaled, val_scaled, test_scaled, window_size=24):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n",
    "\n",
    "    for i in range(window_size, len(train_scaled)):\n",
    "        X_train.append(train_scaled[i-window_size:i, 0])\n",
    "        y_train.append(train_scaled[i, 0])\n",
    "\n",
    "    for i in range(window_size, len(val_scaled)):\n",
    "        X_val.append(val_scaled[i-window_size:i, 0])\n",
    "        y_val.append(val_scaled[i, 0])\n",
    "\n",
    "    for i in range(window_size, len(test_scaled)):\n",
    "        X_test.append(test_scaled[i-window_size:i, 0])\n",
    "        y_test.append(test_scaled[i, 0])\n",
    "\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    X = np.concatenate((X_train, X_val, X_test), axis=0)\n",
    "    y = np.concatenate((y_train, y_val, y_test), axis=0)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, X, y = packager(train_scaled, val_scaled, test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape : (39840, 24, 1)\n",
      "X_test Shape : (168, 24, 1)\n",
      "X_val Shape : (72, 24, 1)\n",
      "X Shape : (40080, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train Shape : {X_train.shape}\")\n",
    "print(f\"X_test Shape : {X_test.shape}\")\n",
    "print(f\"X_val Shape : {X_val.shape}\")\n",
    "print(f\"X Shape : {X.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y_true , y_pred):\n",
    "    from sklearn.metrics import r2_score , mean_absolute_error , mean_squared_error , mean_absolute_percentage_error\n",
    "    \n",
    "    # MAPE hesaplama\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "    # r2 hesaplama\n",
    "    r2 = r2_score(y_true , y_pred)\n",
    "    \n",
    "    # mae hesaplama\n",
    "    mae = mean_absolute_error(y_true , y_pred)\n",
    "\n",
    "    # rmse hesaplama\n",
    "    mse = mean_squared_error(y_true,y_pred)**0.5\n",
    "    \n",
    "    print(f\"\"\"\n",
    "          Mape Score : {mape}\n",
    "          R2 Score : {r2}\n",
    "          MAE Score : {mae}\n",
    "          MSE Score : {mse}\n",
    "          \"\"\")\n",
    "    \n",
    "def eval_plot(y_true , y_pred):\n",
    "    tests = pd.DataFrame(data = y_true , columns=['Real Values'] , index = X_test[:-24].index)\n",
    "    preds = pd.DataFrame(data = y_pred , columns=['Predicts'] , index = future_data[:-24].index)\n",
    "    compare = pd.concat([tests[:-24], preds] , axis= 1)\n",
    "    print(compare.plot())\n",
    "    \n",
    "def eval_df (y_true , y_pred):\n",
    "    compare = pd.DataFrame({'Real Values': y_true, 'Predicts': y_pred}, index=future_data[:-24].index)\n",
    "    print(compare)\n",
    "    \n",
    "def create_submission(future_preds, num):\n",
    "    submission_df = pd.DataFrame({'Tarih': future_data.index, 'Dağıtılan Enerji (MWh)': future_preds})\n",
    "    filename = 'submission{}.csv'.format(num)\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    globals()['submission{}'.format(num)] = submission_df\n",
    "    \n",
    "def preds_plot(data , future_data):\n",
    "    # Gerçek değerleri mavi renkte çizdir\n",
    "    plt.plot(data, color='blue', label='Gerçek Değerler')\n",
    "\n",
    "    # Tahmin edilen değerleri yeşil renkte çizdir\n",
    "    plt.plot(future_data, color='green', label='Tahminler')\n",
    "\n",
    "    # Eksenleri ve grafik başlığını belirle\n",
    "    plt.title('Gerçek Değerler ve Tahminler')\n",
    "    plt.xlabel('Saat')\n",
    "    plt.ylabel('Değer')\n",
    "    plt.legend()\n",
    "\n",
    "    # Grafikleri göster\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "\n",
    "# # Model oluşturma\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, input_shape=(24, 1), return_sequences= True))\n",
    "# model.add(LSTM(25))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# # Modeli eğitme\n",
    "# model.fit(X_train , y_train, epochs= 10, validation_data=(X_val , y_val))\n",
    "\n",
    "# # Modeli değerlendirme\n",
    "# mse = model.evaluate(X_test , y_test)\n",
    "# print('Test MSE: %.3f' % mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for creating and training the LSTM model\n",
    "def create_lstm_model(hidden_size, initial_num_unit, learning_rate = 0.001, epoch=20, batch_size = 1 , window_size = 24 , unit_style= 'decrease' , save=False):\n",
    "    if unit_style == \"decrease\":\n",
    "        return_sequences = [True] * (hidden_size - 1) + [False]\n",
    "        model = Sequential()\n",
    "        for i in range(hidden_size):\n",
    "            if i == 0:\n",
    "                model.add(LSTM(initial_num_unit, input_shape=(window_size, 1), return_sequences=return_sequences[i]))\n",
    "            else:\n",
    "                model.add(LSTM(initial_num_unit // 2**i, return_sequences=return_sequences[i]))\n",
    "        model.add(Dense(1))\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        if save:\n",
    "            return_sequences = [True] * (hidden_size - 1) + [False]\n",
    "            model = Sequential()\n",
    "            for i in range(hidden_size):\n",
    "                if i == 0:\n",
    "                    model.add(LSTM(initial_num_unit, input_shape=(window_size, 1), return_sequences=return_sequences[i]))\n",
    "                else:\n",
    "                    model.add(LSTM(initial_num_unit // 2**i, return_sequences=return_sequences[i]))\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "            model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "            \n",
    "            \n",
    "            # sc = MinMaxScaler(feature_range=(0,1))\n",
    "            # data_scaled = sc.fit_transform(data)\n",
    "            # train_scaled = sc.transform(X_train_temp)\n",
    "            # test_scaled = sc.transform(X_test_temp)\n",
    "\n",
    "            # val_scaled = sc.transform(X_val_temp)\n",
    "            \n",
    "            # X_train, y_train, X_val, y_val, X_test, y_test, X, y = packager(train_scaled, val_scaled, test_scaled)\n",
    "            \n",
    "            \n",
    "            model.fit(X, y, epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            y_pred = model.predict(X_test)\n",
    "            org_y_pred = scaler.inverse_transform(y_pred.reshape(-1,1))\n",
    "            org_y_test = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "            \n",
    "            testScore = mean_absolute_percentage_error(org_y_test, org_y_pred)\n",
    "            \n",
    "            model.save(f'../models/lstm_model_{hidden_size}_{initial_num_unit}_{learning_rate}_{epoch}_{round(testScore, 4)}.h5')\n",
    "        else:\n",
    "            model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            return model\n",
    "        \n",
    "    elif unit_style == 'increase':\n",
    "        return_sequences = [True] * (hidden_size - 1) + [False]\n",
    "        model = Sequential()\n",
    "        for i in range(hidden_size):\n",
    "            if i == 0:\n",
    "                model.add(LSTM(initial_num_unit, input_shape=(window_size, 1), return_sequences=return_sequences[i]))\n",
    "            else:\n",
    "                model.add(LSTM(initial_num_unit * 2**i, return_sequences=return_sequences[i]))\n",
    "        model.add(Dense(1))\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        if save:\n",
    "            model.fit(X, y, epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            model.save(f'../models/lstm_model_{hidden_size}_{initial_num_unit}_{learning_rate}_{epoch}.h5')\n",
    "        else:\n",
    "            model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            return model\n",
    "        \n",
    "    elif unit_style == \"same\":\n",
    "        return_sequences = [True] * (hidden_size - 1) + [False]\n",
    "        model = Sequential()\n",
    "        for i in range(hidden_size):\n",
    "            if i == 0:\n",
    "                model.add(LSTM(initial_num_unit, input_shape=(window_size, 1), return_sequences=return_sequences[i]))\n",
    "            else:\n",
    "                model.add(LSTM(initial_num_unit, return_sequences=return_sequences[i]))\n",
    "        model.add(Dense(1))\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        if save:\n",
    "            model.fit(X, y, epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            model.save(f'../models/lstm_model_{hidden_size}_{initial_num_unit}_{learning_rate}_{epoch}.h5')\n",
    "        else:\n",
    "            model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.001 , Epoch : 10\n",
      "Epoch 1/10\n",
      "39840/39840 [==============================] - 139s 3ms/step - loss: 9.0405e-04 - val_loss: 4.9125e-04\n",
      "Epoch 2/10\n",
      "39840/39840 [==============================] - 138s 3ms/step - loss: 3.8235e-04 - val_loss: 2.1770e-04\n",
      "Epoch 3/10\n",
      "39840/39840 [==============================] - 138s 3ms/step - loss: 3.1059e-04 - val_loss: 2.2983e-04\n",
      "Epoch 4/10\n",
      "39840/39840 [==============================] - 133s 3ms/step - loss: 2.6888e-04 - val_loss: 2.0374e-04\n",
      "Epoch 5/10\n",
      "39840/39840 [==============================] - 128s 3ms/step - loss: 2.4937e-04 - val_loss: 1.1818e-04\n",
      "Epoch 6/10\n",
      "39840/39840 [==============================] - 131s 3ms/step - loss: 2.3667e-04 - val_loss: 2.0523e-04\n",
      "Epoch 7/10\n",
      "39840/39840 [==============================] - 129s 3ms/step - loss: 2.2240e-04 - val_loss: 1.9802e-04\n",
      "Epoch 8/10\n",
      "39840/39840 [==============================] - 131s 3ms/step - loss: 2.1479e-04 - val_loss: 1.7078e-04\n",
      "Epoch 9/10\n",
      "39840/39840 [==============================] - 129s 3ms/step - loss: 2.0670e-04 - val_loss: 1.3239e-04\n",
      "Epoch 10/10\n",
      "39840/39840 [==============================] - 132s 3ms/step - loss: 2.0061e-04 - val_loss: 1.7801e-04\n",
      "1245/1245 [==============================] - 2s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.001 , Epoch : 10 , Unit Style : Decrease \n",
      "Train Score : 0.015287822975360233 , Val Score : 0.01388973997192334 , Test Score : 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "40080/40080 [==============================] - 134s 3ms/step - loss: 9.3661e-04\n",
      "Epoch 2/10\n",
      "40080/40080 [==============================] - 127s 3ms/step - loss: 3.7059e-04\n",
      "Epoch 3/10\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 2.8577e-04\n",
      "Epoch 4/10\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 2.5529e-04\n",
      "Epoch 5/10\n",
      "40080/40080 [==============================] - 131s 3ms/step - loss: 2.3793e-04\n",
      "Epoch 6/10\n",
      "40080/40080 [==============================] - 129s 3ms/step - loss: 2.2716e-04\n",
      "Epoch 7/10\n",
      "40080/40080 [==============================] - 131s 3ms/step - loss: 2.1563e-04\n",
      "Epoch 8/10\n",
      "40080/40080 [==============================] - 133s 3ms/step - loss: 2.0612e-04\n",
      "Epoch 9/10\n",
      "40080/40080 [==============================] - 132s 3ms/step - loss: 1.9906e-04\n",
      "Epoch 10/10\n",
      "40080/40080 [==============================] - 135s 3ms/step - loss: 1.9131e-04\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.001 , Epoch : 20\n",
      "Epoch 1/20\n",
      "39840/39840 [==============================] - 134s 3ms/step - loss: 9.4128e-04 - val_loss: 4.4601e-04\n",
      "Epoch 2/20\n",
      "39840/39840 [==============================] - 140s 4ms/step - loss: 3.5897e-04 - val_loss: 2.2009e-04\n",
      "Epoch 3/20\n",
      "39840/39840 [==============================] - 136s 3ms/step - loss: 2.9693e-04 - val_loss: 2.3295e-04\n",
      "Epoch 4/20\n",
      "39840/39840 [==============================] - 135s 3ms/step - loss: 2.6973e-04 - val_loss: 1.9560e-04\n",
      "Epoch 5/20\n",
      "39840/39840 [==============================] - 135s 3ms/step - loss: 2.5174e-04 - val_loss: 1.1635e-04\n",
      "Epoch 6/20\n",
      "39840/39840 [==============================] - 136s 3ms/step - loss: 2.3665e-04 - val_loss: 2.0316e-04\n",
      "Epoch 7/20\n",
      "39840/39840 [==============================] - 150s 4ms/step - loss: 2.2056e-04 - val_loss: 1.5464e-04\n",
      "Epoch 8/20\n",
      "39840/39840 [==============================] - 183s 5ms/step - loss: 2.1063e-04 - val_loss: 1.2070e-04\n",
      "Epoch 9/20\n",
      "39840/39840 [==============================] - 214s 5ms/step - loss: 2.0221e-04 - val_loss: 1.7770e-04\n",
      "Epoch 10/20\n",
      "39840/39840 [==============================] - 217s 5ms/step - loss: 1.9514e-04 - val_loss: 1.9547e-04\n",
      "Epoch 11/20\n",
      "39840/39840 [==============================] - 228s 6ms/step - loss: 1.8686e-04 - val_loss: 9.3347e-05\n",
      "Epoch 12/20\n",
      "39840/39840 [==============================] - 225s 6ms/step - loss: 1.8108e-04 - val_loss: 9.7688e-05\n",
      "Epoch 13/20\n",
      "39840/39840 [==============================] - 224s 6ms/step - loss: 1.7809e-04 - val_loss: 1.5713e-04\n",
      "Epoch 14/20\n",
      "39840/39840 [==============================] - 225s 6ms/step - loss: 1.7222e-04 - val_loss: 1.3958e-04\n",
      "Epoch 15/20\n",
      "39840/39840 [==============================] - 224s 6ms/step - loss: 1.6817e-04 - val_loss: 1.5918e-04\n",
      "Epoch 16/20\n",
      "39840/39840 [==============================] - 225s 6ms/step - loss: 1.6494e-04 - val_loss: 8.9446e-05\n",
      "Epoch 17/20\n",
      "39840/39840 [==============================] - 224s 6ms/step - loss: 1.5966e-04 - val_loss: 1.0355e-04\n",
      "Epoch 18/20\n",
      "39840/39840 [==============================] - 225s 6ms/step - loss: 1.5640e-04 - val_loss: 1.2801e-04\n",
      "Epoch 19/20\n",
      "39840/39840 [==============================] - 224s 6ms/step - loss: 1.5491e-04 - val_loss: 7.7491e-05\n",
      "Epoch 20/20\n",
      "39840/39840 [==============================] - 224s 6ms/step - loss: 1.5068e-04 - val_loss: 8.0605e-05\n",
      "1245/1245 [==============================] - 4s 3ms/step\n",
      "3/3 [==============================] - 1s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.001 , Epoch : 20 , Unit Style : Decrease \n",
      "Train Score : 0.01341417063010933 , Val Score : 0.0085247222101962 , Test Score : 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "40080/40080 [==============================] - 225s 6ms/step - loss: 0.0011\n",
      "Epoch 2/20\n",
      "40080/40080 [==============================] - 225s 6ms/step - loss: 3.7701e-04\n",
      "Epoch 3/20\n",
      "40080/40080 [==============================] - 222s 6ms/step - loss: 2.9710e-04\n",
      "Epoch 4/20\n",
      "40080/40080 [==============================] - 227s 6ms/step - loss: 2.6868e-04\n",
      "Epoch 5/20\n",
      "40080/40080 [==============================] - 220s 5ms/step - loss: 2.4975e-04\n",
      "Epoch 6/20\n",
      "40080/40080 [==============================] - 220s 5ms/step - loss: 2.3528e-04\n",
      "Epoch 7/20\n",
      "40080/40080 [==============================] - 223s 6ms/step - loss: 2.2057e-04\n",
      "Epoch 8/20\n",
      "40080/40080 [==============================] - 225s 6ms/step - loss: 2.0827e-04\n",
      "Epoch 9/20\n",
      "40080/40080 [==============================] - 226s 6ms/step - loss: 1.9863e-04\n",
      "Epoch 10/20\n",
      "40080/40080 [==============================] - 224s 6ms/step - loss: 1.9018e-04\n",
      "Epoch 11/20\n",
      "40080/40080 [==============================] - 225s 6ms/step - loss: 1.8321e-04\n",
      "Epoch 12/20\n",
      "40080/40080 [==============================] - 189s 5ms/step - loss: 1.7562e-04\n",
      "Epoch 13/20\n",
      "40080/40080 [==============================] - 138s 3ms/step - loss: 1.6936e-04\n",
      "Epoch 14/20\n",
      "40080/40080 [==============================] - 129s 3ms/step - loss: 1.6391e-04\n",
      "Epoch 15/20\n",
      "40080/40080 [==============================] - 129s 3ms/step - loss: 1.5990e-04\n",
      "Epoch 16/20\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 1.5521e-04\n",
      "Epoch 17/20\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 1.5095e-04\n",
      "Epoch 18/20\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 1.4836e-04\n",
      "Epoch 19/20\n",
      "40080/40080 [==============================] - 132s 3ms/step - loss: 1.4552e-04\n",
      "Epoch 20/20\n",
      "40080/40080 [==============================] - 133s 3ms/step - loss: 1.4238e-04\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.001 , Epoch : 30\n",
      "Epoch 1/30\n",
      "39840/39840 [==============================] - 132s 3ms/step - loss: 8.8191e-04 - val_loss: 5.2176e-04\n",
      "Epoch 2/30\n",
      "39840/39840 [==============================] - 131s 3ms/step - loss: 4.0213e-04 - val_loss: 2.9967e-04\n",
      "Epoch 3/30\n",
      "39840/39840 [==============================] - 134s 3ms/step - loss: 3.2804e-04 - val_loss: 2.2871e-04\n",
      "Epoch 4/30\n",
      "39840/39840 [==============================] - 132s 3ms/step - loss: 2.7971e-04 - val_loss: 1.8276e-04\n",
      "Epoch 5/30\n",
      "39840/39840 [==============================] - 128s 3ms/step - loss: 2.5374e-04 - val_loss: 1.4022e-04\n",
      "Epoch 6/30\n",
      "39840/39840 [==============================] - 134s 3ms/step - loss: 2.3689e-04 - val_loss: 1.9890e-04\n",
      "Epoch 7/30\n",
      "39840/39840 [==============================] - 131s 3ms/step - loss: 2.1835e-04 - val_loss: 2.2257e-04\n",
      "Epoch 8/30\n",
      "39840/39840 [==============================] - 127s 3ms/step - loss: 2.0876e-04 - val_loss: 1.3813e-04\n",
      "Epoch 9/30\n",
      "39840/39840 [==============================] - 126s 3ms/step - loss: 2.0087e-04 - val_loss: 1.1412e-04\n",
      "Epoch 10/30\n",
      "39840/39840 [==============================] - 126s 3ms/step - loss: 1.9334e-04 - val_loss: 1.7638e-04\n",
      "Epoch 11/30\n",
      "39840/39840 [==============================] - 129s 3ms/step - loss: 1.8591e-04 - val_loss: 9.1700e-05\n",
      "Epoch 12/30\n",
      "39840/39840 [==============================] - 131s 3ms/step - loss: 1.7922e-04 - val_loss: 1.0191e-04\n",
      "Epoch 13/30\n",
      "39840/39840 [==============================] - 124s 3ms/step - loss: 1.7433e-04 - val_loss: 9.2816e-05\n",
      "Epoch 14/30\n",
      "39840/39840 [==============================] - 125s 3ms/step - loss: 1.6844e-04 - val_loss: 1.1360e-04\n",
      "Epoch 15/30\n",
      "39840/39840 [==============================] - 125s 3ms/step - loss: 1.6564e-04 - val_loss: 1.4780e-04\n",
      "Epoch 16/30\n",
      "39840/39840 [==============================] - 127s 3ms/step - loss: 1.6196e-04 - val_loss: 7.9202e-05\n",
      "Epoch 17/30\n",
      "39840/39840 [==============================] - 130s 3ms/step - loss: 1.5695e-04 - val_loss: 1.4081e-04\n",
      "Epoch 18/30\n",
      "39840/39840 [==============================] - 146s 4ms/step - loss: 1.5352e-04 - val_loss: 1.7836e-04\n",
      "Epoch 19/30\n",
      "39840/39840 [==============================] - 221s 6ms/step - loss: 1.5141e-04 - val_loss: 1.0369e-04\n",
      "Epoch 20/30\n",
      "39840/39840 [==============================] - 220s 6ms/step - loss: 1.4744e-04 - val_loss: 8.3126e-05\n",
      "Epoch 21/30\n",
      "39840/39840 [==============================] - 220s 6ms/step - loss: 1.4547e-04 - val_loss: 9.8618e-05\n",
      "Epoch 22/30\n",
      "39840/39840 [==============================] - 219s 5ms/step - loss: 1.4355e-04 - val_loss: 1.8412e-04\n",
      "Epoch 23/30\n",
      "39840/39840 [==============================] - 218s 5ms/step - loss: 1.4046e-04 - val_loss: 7.7742e-05\n",
      "Epoch 24/30\n",
      "39840/39840 [==============================] - 206s 5ms/step - loss: 1.3971e-04 - val_loss: 9.5271e-05\n",
      "Epoch 25/30\n",
      "39840/39840 [==============================] - 127s 3ms/step - loss: 1.3705e-04 - val_loss: 1.4823e-04\n",
      "Epoch 26/30\n",
      "39840/39840 [==============================] - 129s 3ms/step - loss: 1.3378e-04 - val_loss: 1.3296e-04\n",
      "Epoch 27/30\n",
      "39840/39840 [==============================] - 127s 3ms/step - loss: 1.3286e-04 - val_loss: 9.7708e-05\n",
      "Epoch 28/30\n",
      "39840/39840 [==============================] - 127s 3ms/step - loss: 1.3190e-04 - val_loss: 1.0053e-04\n",
      "Epoch 29/30\n",
      "39840/39840 [==============================] - 128s 3ms/step - loss: 1.2994e-04 - val_loss: 1.1229e-04\n",
      "Epoch 30/30\n",
      "39840/39840 [==============================] - 129s 3ms/step - loss: 1.2864e-04 - val_loss: 1.7008e-04\n",
      "1245/1245 [==============================] - 3s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.001 , Epoch : 30 , Unit Style : Decrease \n",
      "Train Score : 0.013948833681912737 , Val Score : 0.01231234351735724 , Test Score : 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/30\n",
      "40080/40080 [==============================] - 130s 3ms/step - loss: 9.7552e-04\n",
      "Epoch 2/30\n",
      "40080/40080 [==============================] - 127s 3ms/step - loss: 3.8438e-04\n",
      "Epoch 3/30\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 3.1159e-04\n",
      "Epoch 4/30\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 2.7636e-04\n",
      "Epoch 5/30\n",
      "40080/40080 [==============================] - 124s 3ms/step - loss: 2.5255e-04\n",
      "Epoch 6/30\n",
      "40080/40080 [==============================] - 125s 3ms/step - loss: 2.3694e-04\n",
      "Epoch 7/30\n",
      "40080/40080 [==============================] - 124s 3ms/step - loss: 2.1956e-04\n",
      "Epoch 8/30\n",
      "40080/40080 [==============================] - 125s 3ms/step - loss: 2.0925e-04\n",
      "Epoch 9/30\n",
      "40080/40080 [==============================] - 124s 3ms/step - loss: 2.0003e-04\n",
      "Epoch 10/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.9248e-04\n",
      "Epoch 11/30\n",
      "40080/40080 [==============================] - 122s 3ms/step - loss: 1.8564e-04\n",
      "Epoch 12/30\n",
      "40080/40080 [==============================] - 124s 3ms/step - loss: 1.8065e-04\n",
      "Epoch 13/30\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 1.7458e-04\n",
      "Epoch 14/30\n",
      "40080/40080 [==============================] - 125s 3ms/step - loss: 1.6976e-04\n",
      "Epoch 15/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.6491e-04\n",
      "Epoch 16/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.5997e-04\n",
      "Epoch 17/30\n",
      "40080/40080 [==============================] - 121s 3ms/step - loss: 1.5702e-04\n",
      "Epoch 18/30\n",
      "40080/40080 [==============================] - 122s 3ms/step - loss: 1.5296e-04\n",
      "Epoch 19/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.5037e-04\n",
      "Epoch 20/30\n",
      "40080/40080 [==============================] - 122s 3ms/step - loss: 1.4635e-04\n",
      "Epoch 21/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.4300e-04\n",
      "Epoch 22/30\n",
      "40080/40080 [==============================] - 122s 3ms/step - loss: 1.4018e-04\n",
      "Epoch 23/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.3843e-04\n",
      "Epoch 24/30\n",
      "40080/40080 [==============================] - 122s 3ms/step - loss: 1.3581e-04\n",
      "Epoch 25/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.3348e-04\n",
      "Epoch 26/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.3251e-04\n",
      "Epoch 27/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.2872e-04\n",
      "Epoch 28/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.2837e-04\n",
      "Epoch 29/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.2624e-04\n",
      "Epoch 30/30\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 1.2500e-04\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.01 , Epoch : 10\n",
      "Epoch 1/10\n",
      "39840/39840 [==============================] - 124s 3ms/step - loss: 9.5374e-04 - val_loss: 3.7879e-04\n",
      "Epoch 2/10\n",
      "39840/39840 [==============================] - 121s 3ms/step - loss: 5.2240e-04 - val_loss: 5.7563e-04\n",
      "Epoch 3/10\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 4.3613e-04 - val_loss: 3.1568e-04\n",
      "Epoch 4/10\n",
      "39840/39840 [==============================] - 121s 3ms/step - loss: 3.9873e-04 - val_loss: 2.4696e-04\n",
      "Epoch 5/10\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 3.7572e-04 - val_loss: 1.2173e-04\n",
      "Epoch 6/10\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 3.5010e-04 - val_loss: 1.5764e-04\n",
      "Epoch 7/10\n",
      "39840/39840 [==============================] - 121s 3ms/step - loss: 3.3405e-04 - val_loss: 1.7096e-04\n",
      "Epoch 8/10\n",
      "39840/39840 [==============================] - 121s 3ms/step - loss: 3.2384e-04 - val_loss: 1.8682e-04\n",
      "Epoch 9/10\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 3.1460e-04 - val_loss: 3.7935e-04\n",
      "Epoch 10/10\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 3.0640e-04 - val_loss: 2.2117e-04\n",
      "1245/1245 [==============================] - 2s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.01 , Epoch : 10 , Unit Style : Decrease \n",
      "Train Score : 0.021716573076594754 , Val Score : 0.013717249345215362 , Test Score : 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/10\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 9.6894e-04\n",
      "Epoch 2/10\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 5.5968e-04\n",
      "Epoch 3/10\n",
      "40080/40080 [==============================] - 122s 3ms/step - loss: 5.0835e-04\n",
      "Epoch 4/10\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 4.2584e-04\n",
      "Epoch 5/10\n",
      "40080/40080 [==============================] - 122s 3ms/step - loss: 4.0136e-04\n",
      "Epoch 6/10\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 3.7617e-04\n",
      "Epoch 7/10\n",
      "40080/40080 [==============================] - 122s 3ms/step - loss: 4.1683e-04\n",
      "Epoch 8/10\n",
      "40080/40080 [==============================] - 122s 3ms/step - loss: 0.0067\n",
      "Epoch 9/10\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 0.0021\n",
      "Epoch 10/10\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 9.3270e-04\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.01 , Epoch : 20\n",
      "Epoch 1/20\n",
      "39840/39840 [==============================] - 124s 3ms/step - loss: 9.7153e-04 - val_loss: 4.3610e-04\n",
      "Epoch 2/20\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 5.8637e-04 - val_loss: 4.3392e-04\n",
      "Epoch 3/20\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 5.0258e-04 - val_loss: 5.0663e-04\n",
      "Epoch 4/20\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 4.3671e-04 - val_loss: 2.7295e-04\n",
      "Epoch 5/20\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 4.0245e-04 - val_loss: 1.7349e-04\n",
      "Epoch 6/20\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 3.6850e-04 - val_loss: 1.9796e-04\n",
      "Epoch 7/20\n",
      "39840/39840 [==============================] - 125s 3ms/step - loss: 3.4813e-04 - val_loss: 1.6967e-04\n",
      "Epoch 8/20\n",
      "39840/39840 [==============================] - 124s 3ms/step - loss: 3.3697e-04 - val_loss: 2.3576e-04\n",
      "Epoch 9/20\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 0.0069 - val_loss: 0.0237\n",
      "Epoch 10/20\n",
      "39840/39840 [==============================] - 124s 3ms/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 11/20\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 12/20\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 13/20\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0042 - val_loss: 8.9870e-04\n",
      "Epoch 14/20\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 15/20\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 16/20\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 17/20\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 0.0079 - val_loss: 9.5067e-04\n",
      "Epoch 18/20\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 19/20\n",
      "39840/39840 [==============================] - 124s 3ms/step - loss: 0.0035 - val_loss: 0.0010\n",
      "Epoch 20/20\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "1245/1245 [==============================] - 2s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.01 , Epoch : 20 , Unit Style : Decrease \n",
      "Train Score : 0.04184272580073132 , Val Score : 0.041925456503908276 , Test Score : 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/20\n",
      "40080/40080 [==============================] - 124s 3ms/step - loss: 9.5966e-04\n",
      "Epoch 2/20\n",
      "40080/40080 [==============================] - 125s 3ms/step - loss: 5.8365e-04\n",
      "Epoch 3/20\n",
      "40080/40080 [==============================] - 125s 3ms/step - loss: 5.2207e-04\n",
      "Epoch 4/20\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 0.0129\n",
      "Epoch 5/20\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 0.1548\n",
      "Epoch 6/20\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 0.0052\n",
      "Epoch 7/20\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 7.2384e-04\n",
      "Epoch 8/20\n",
      "40080/40080 [==============================] - 127s 3ms/step - loss: 6.6893e-04\n",
      "Epoch 9/20\n",
      "40080/40080 [==============================] - 127s 3ms/step - loss: 0.0014\n",
      "Epoch 10/20\n",
      "40080/40080 [==============================] - 127s 3ms/step - loss: 8.3884e-04\n",
      "Epoch 11/20\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 4.6040e-04\n",
      "Epoch 12/20\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 4.5870e-04\n",
      "Epoch 13/20\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 3.8521e-04\n",
      "Epoch 14/20\n",
      "40080/40080 [==============================] - 127s 3ms/step - loss: 0.0029\n",
      "Epoch 15/20\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 4.2987e-04\n",
      "Epoch 16/20\n",
      "40080/40080 [==============================] - 127s 3ms/step - loss: 3.8576e-04\n",
      "Epoch 17/20\n",
      "40080/40080 [==============================] - 127s 3ms/step - loss: 3.8952e-04\n",
      "Epoch 18/20\n",
      "40080/40080 [==============================] - 125s 3ms/step - loss: 3.4001e-04\n",
      "Epoch 19/20\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 3.2670e-04\n",
      "Epoch 20/20\n",
      "40080/40080 [==============================] - 123s 3ms/step - loss: 3.2154e-04\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.01 , Epoch : 30\n",
      "Epoch 1/30\n",
      "39840/39840 [==============================] - 125s 3ms/step - loss: 9.3882e-04 - val_loss: 5.0474e-04\n",
      "Epoch 2/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 5.0296e-04 - val_loss: 2.3973e-04\n",
      "Epoch 3/30\n",
      "39840/39840 [==============================] - 124s 3ms/step - loss: 4.3158e-04 - val_loss: 3.0369e-04\n",
      "Epoch 4/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 3.9303e-04 - val_loss: 2.3484e-04\n",
      "Epoch 5/30\n",
      "39840/39840 [==============================] - 124s 3ms/step - loss: 4.3943e-04 - val_loss: 1.9418e-04\n",
      "Epoch 6/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 3.5097e-04 - val_loss: 1.6885e-04\n",
      "Epoch 7/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 3.3349e-04 - val_loss: 1.4715e-04\n",
      "Epoch 8/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 5.9542e-04 - val_loss: 0.0569\n",
      "Epoch 9/30\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 0.0093 - val_loss: 0.0012\n",
      "Epoch 10/30\n",
      "39840/39840 [==============================] - 124s 3ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 11/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0041 - val_loss: 9.4561e-04\n",
      "Epoch 12/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 13/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0021 - val_loss: 6.1439e-04\n",
      "Epoch 14/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 8.3038e-04 - val_loss: 3.3267e-04\n",
      "Epoch 15/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 6.2180e-04 - val_loss: 3.3313e-04\n",
      "Epoch 16/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0159 - val_loss: 0.0018\n",
      "Epoch 17/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0115 - val_loss: 0.0047\n",
      "Epoch 18/30\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 19/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 20/30\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 0.0014 - val_loss: 5.9784e-04\n",
      "Epoch 21/30\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 22/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0031 - val_loss: 8.5901e-04\n",
      "Epoch 23/30\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 0.0036 - val_loss: 5.1260e-04\n",
      "Epoch 24/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 25/30\n",
      "39840/39840 [==============================] - 123s 3ms/step - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 26/30\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 27/30\n",
      "39840/39840 [==============================] - 122s 3ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 28/30\n",
      "39840/39840 [==============================] - 124s 3ms/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 29/30\n",
      "39840/39840 [==============================] - 127s 3ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 30/30\n",
      "39840/39840 [==============================] - 125s 3ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "1245/1245 [==============================] - 2s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 32 , Learning Rate : 0.01 , Epoch : 30 , Unit Style : Decrease \n",
      "Train Score : 0.06194132162104838 , Val Score : 0.03818054207788769 , Test Score : 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/30\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 9.7203e-04\n",
      "Epoch 2/30\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 5.2006e-04\n",
      "Epoch 3/30\n",
      "40080/40080 [==============================] - 173s 4ms/step - loss: 4.2778e-04\n",
      "Epoch 4/30\n",
      "40080/40080 [==============================] - 156s 4ms/step - loss: 3.8829e-04\n",
      "Epoch 5/30\n",
      "40080/40080 [==============================] - 140s 3ms/step - loss: 3.6883e-04\n",
      "Epoch 6/30\n",
      "40080/40080 [==============================] - 140s 4ms/step - loss: 0.0012\n",
      "Epoch 7/30\n",
      "40080/40080 [==============================] - 140s 4ms/step - loss: 3.6327e-04\n",
      "Epoch 8/30\n",
      "40080/40080 [==============================] - 137s 3ms/step - loss: 0.0014\n",
      "Epoch 9/30\n",
      "40080/40080 [==============================] - 133s 3ms/step - loss: 0.0113\n",
      "Epoch 10/30\n",
      "40080/40080 [==============================] - 133s 3ms/step - loss: 0.0064\n",
      "Epoch 11/30\n",
      "40080/40080 [==============================] - 135s 3ms/step - loss: 0.0046\n",
      "Epoch 12/30\n",
      "40080/40080 [==============================] - 133s 3ms/step - loss: 0.0045\n",
      "Epoch 13/30\n",
      "40080/40080 [==============================] - 134s 3ms/step - loss: 0.0045\n",
      "Epoch 14/30\n",
      "40080/40080 [==============================] - 134s 3ms/step - loss: 0.0044\n",
      "Epoch 15/30\n",
      "40080/40080 [==============================] - 134s 3ms/step - loss: 0.0034\n",
      "Epoch 16/30\n",
      "40080/40080 [==============================] - 134s 3ms/step - loss: 9.2748e-04\n",
      "Epoch 17/30\n",
      "40080/40080 [==============================] - 132s 3ms/step - loss: 0.0013\n",
      "Epoch 18/30\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 9.1035e-04\n",
      "Epoch 19/30\n",
      "40080/40080 [==============================] - 129s 3ms/step - loss: 0.0011\n",
      "Epoch 20/30\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 8.5194e-04\n",
      "Epoch 21/30\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 8.0947e-04\n",
      "Epoch 22/30\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 7.4329e-04\n",
      "Epoch 23/30\n",
      "40080/40080 [==============================] - 126s 3ms/step - loss: 7.4546e-04\n",
      "Epoch 24/30\n",
      "40080/40080 [==============================] - 127s 3ms/step - loss: 6.7168e-04\n",
      "Epoch 25/30\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 6.5229e-04\n",
      "Epoch 26/30\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 6.5859e-04\n",
      "Epoch 27/30\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 7.1086e-04\n",
      "Epoch 28/30\n",
      "40080/40080 [==============================] - 128s 3ms/step - loss: 6.4700e-04\n",
      "Epoch 29/30\n",
      "40080/40080 [==============================] - 129s 3ms/step - loss: 0.0012\n",
      "Epoch 30/30\n",
      "40080/40080 [==============================] - 129s 3ms/step - loss: 6.2790e-04\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Hidden size : 2 , Initial Num neurons : 16 , Learning Rate : 0.001 , Epoch : 10\n",
      "Epoch 1/10\n",
      "11861/39840 [=======>......................] - ETA: 1:32 - loss: 0.0028"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m epochs:\n\u001b[0;32m     27\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHidden size : \u001b[39m\u001b[39m{\u001b[39;00mhidden_size\u001b[39m}\u001b[39;00m\u001b[39m , Initial Num neurons : \u001b[39m\u001b[39m{\u001b[39;00minitial_num_unit\u001b[39m}\u001b[39;00m\u001b[39m , Learning Rate : \u001b[39m\u001b[39m{\u001b[39;00mlearning_rate\u001b[39m}\u001b[39;00m\u001b[39m , Epoch : \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m     model \u001b[39m=\u001b[39m create_lstm_model(hidden_size, initial_num_unit, learning_rate , epoch \u001b[39m=\u001b[39;49m epoch , unit_style\u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mdecrease\u001b[39;49m\u001b[39m'\u001b[39;49m )\n\u001b[0;32m     31\u001b[0m     trainPredict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_train)\n\u001b[0;32m     32\u001b[0m     valPredict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val)\n",
      "Cell \u001b[1;32mIn[18], line 46\u001b[0m, in \u001b[0;36mcreate_lstm_model\u001b[1;34m(hidden_size, initial_num_unit, learning_rate, epoch, batch_size, window_size, unit_style, save)\u001b[0m\n\u001b[0;32m     44\u001b[0m         model\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../models/lstm_model_\u001b[39m\u001b[39m{\u001b[39;00mhidden_size\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00minitial_num_unit\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mlearning_rate\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(testScore,\u001b[39m \u001b[39m\u001b[39m4\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m         model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), epochs\u001b[39m=\u001b[39;49mepoch, batch_size\u001b[39m=\u001b[39;49mbatch_size, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     47\u001b[0m         \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m     49\u001b[0m \u001b[39melif\u001b[39;00m unit_style \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mincrease\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Emincan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Emincan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define empty lists to store model results\n",
    "hidden_sizes = []\n",
    "initial_units_list = []\n",
    "learning_rates_list = []\n",
    "epochs_list = []\n",
    "train_scores = []\n",
    "val_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "hidden_layer_sizes = [2,3]\n",
    "initial_num_units = [32,16]\n",
    "learning_rates = [0.001, 0.01]\n",
    "epochs = [10, 20, 30]\n",
    "\n",
    "# Define the number of epochs and batch size to use in training\n",
    "batch_size = 1\n",
    "\n",
    "# Define the number of previous time steps to use as input features\n",
    "window_size = 24\n",
    "        \n",
    "        \n",
    "for hidden_size in hidden_layer_sizes:\n",
    "    for initial_num_unit in initial_num_units:\n",
    "        for learning_rate in learning_rates:\n",
    "            for epoch in epochs:\n",
    "                print(f\"Hidden size : {hidden_size} , Initial Num neurons : {initial_num_unit} , Learning Rate : {learning_rate} , Epoch : {epoch}\")\n",
    "                model = create_lstm_model(hidden_size, initial_num_unit, learning_rate , batch_size= batch_size , epoch = epoch , unit_style= 'decrease' )\n",
    "                \n",
    "                \n",
    "                trainPredict = model.predict(X_train)\n",
    "                valPredict = model.predict(X_val)\n",
    "                testPredict = model.predict(X_test)\n",
    "                org_y_train_pred = scaler.inverse_transform(trainPredict)\n",
    "                org_y_val_pred = scaler.inverse_transform(valPredict)\n",
    "                org_y_test_pred = scaler.inverse_transform(testPredict)\n",
    "                \n",
    "                org_y_train = scaler.inverse_transform(y_train.reshape(-1,1))\n",
    "                org_y_val = scaler.inverse_transform(y_val.reshape(-1,1))\n",
    "                org_y_test = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "                \n",
    "                trainScore = mean_absolute_percentage_error(org_y_train, org_y_train_pred)\n",
    "                valScore = mean_absolute_percentage_error(org_y_val, org_y_val_pred)\n",
    "                testScore = mean_absolute_percentage_error(org_y_test_pred, org_y_test_pred)\n",
    "\n",
    "\n",
    "                # Append results to lists\n",
    "                hidden_sizes.append(hidden_size)\n",
    "                initial_units_list.append(initial_num_unit)\n",
    "                learning_rates_list.append(learning_rate)\n",
    "                epochs_list.append(epoch)\n",
    "                train_scores.append(trainScore)\n",
    "                val_scores.append(valScore)\n",
    "                test_scores.append(testScore)\n",
    "                print(f\"Hidden size : {hidden_size} , Initial Num neurons : {initial_num_unit} , Learning Rate : {learning_rate} , Epoch : {epoch} , Unit Style : {'Decrease'} \")\n",
    "                print(f\"Train Score : {trainScore} , Val Score : {valScore} , Test Score : {testScore}\")\n",
    "                print(\"--------------------------------------------------------------------------------\")\n",
    "                if testScore < 0.02 :\n",
    "                    create_lstm_model(hidden_size , initial_num_unit , learning_rate , batch_size = batch_size , epoch = epoch, save= True)\n",
    "\n",
    "# Create dataframe from results\n",
    "results_df = pd.DataFrame({\n",
    "    'HiddenSize': hidden_sizes,\n",
    "    'Initial Num Neurons': initial_units_list,\n",
    "    'LearningRate': learning_rates_list,\n",
    "    'Epoch': epochs_list,\n",
    "    'TrainScore': train_scores,\n",
    "    'valScore': val_scores,\n",
    "    'TestScore': test_scores\n",
    "}).sort_values(by='TestScore' , ascending=False)\n",
    "\n",
    "# Print dataframe\n",
    "results_df.style.format(\"{:.2%}\").background_gradient(cmap=\"Blues\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataframe\n",
    "results_df.style.format(\"{:.2%}\").background_gradient(cmap=\"Blues\")\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test | Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
