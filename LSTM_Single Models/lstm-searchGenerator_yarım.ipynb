{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_data = pd.read_csv(\"future.csv\").drop('Unnamed: 0' , axis = 1)\n",
    "future_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tarih'] = pd.to_datetime(data['Tarih'])\n",
    "future_data['Tarih'] = pd.to_datetime(future_data['Tarih'])\n",
    "data.set_index('Tarih', inplace=True)\n",
    "future_data.set_index('Tarih' , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train | Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed ayarlamak\n",
    "seed_value = 34\n",
    "tf.keras.utils.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_temp = data.loc[data.index > '2022-07-23 23:00:00'].copy()\n",
    "X_train_temp = data.loc[data.index <= '2022-07-23 23:00:00'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_temp = X_train_temp[-96:]\n",
    "X_train_temp = X_train_temp[:-96]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "train_scaled = scaler.fit_transform(X_train_temp)\n",
    "test_scaled = scaler.transform(X_test_temp)\n",
    "\n",
    "val_scaled = scaler.transform(X_val_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu işlemler karışıyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "# Veri jeneratörlerini oluşturma\n",
    "train_gen = TimeseriesGenerator(train_scaled, train_scaled, length=24, batch_size=1)\n",
    "val_gen = TimeseriesGenerator(val_scaled, val_scaled, length=24, batch_size=1)\n",
    "test_gen = TimeseriesGenerator(test_scaled, test_scaled, length=24, batch_size=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y_true , y_pred):\n",
    "    from sklearn.metrics import r2_score , mean_absolute_error , mean_squared_error , mean_absolute_percentage_error\n",
    "    \n",
    "    # MAPE hesaplama\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "    # r2 hesaplama\n",
    "    r2 = r2_score(y_true , y_pred)\n",
    "    \n",
    "    # mae hesaplama\n",
    "    mae = mean_absolute_error(y_true , y_pred)\n",
    "\n",
    "    # rmse hesaplama\n",
    "    mse = mean_squared_error(y_true,y_pred)**0.5\n",
    "    \n",
    "    print(f\"\"\"\n",
    "          Mape Score : {mape}\n",
    "          R2 Score : {r2}\n",
    "          MAE Score : {mae}\n",
    "          MSE Score : {mse}\n",
    "          \"\"\")\n",
    "    \n",
    "def eval_plot(y_true , y_pred):\n",
    "    tests = pd.DataFrame(data = y_true , columns=['Real Values'] , index = X_test[:-24].index)\n",
    "    preds = pd.DataFrame(data = y_pred , columns=['Predicts'] , index = future_data[:-24].index)\n",
    "    compare = pd.concat([tests[:-24], preds] , axis= 1)\n",
    "    print(compare.plot())\n",
    "    \n",
    "def eval_df (y_true , y_pred):\n",
    "    compare = pd.DataFrame({'Real Values': y_true, 'Predicts': y_pred}, index=future_data[:-24].index)\n",
    "    print(compare)\n",
    "    \n",
    "def create_submission(future_preds, num):\n",
    "    submission_df = pd.DataFrame({'Tarih': future_data.index, 'Dağıtılan Enerji (MWh)': future_preds})\n",
    "    filename = 'submission{}.csv'.format(num)\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    globals()['submission{}'.format(num)] = submission_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Model oluşturma\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(24, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Veri jeneratörlerini oluşturma\n",
    "train_gen = TimeseriesGenerator(train_scaled, train_scaled, length=24, batch_size=1)\n",
    "val_gen = TimeseriesGenerator(val_scaled, val_scaled, length=24, batch_size=1)\n",
    "test_gen = TimeseriesGenerator(test_scaled, test_scaled, length=24, batch_size=1)\n",
    "\n",
    "# Modeli eğitme\n",
    "model.fit(train_gen, epochs=3, validation_data=val_gen)\n",
    "\n",
    "# Modeli değerlendirme\n",
    "mse = model.evaluate_generator(test_gen)\n",
    "print('Test MSE: %.3f' % mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for creating and training the LSTM model\n",
    "def create_lstm_model(hidden_size, initial_num_unit, learning_rate, epoch=20, batch_size = 16 , look_back = 24 , unit_style= 'decrease' , save=False):\n",
    "    if unit_style == \"decrease\":\n",
    "        return_sequences = [True] * (hidden_size - 1) + [False]\n",
    "        model = Sequential()\n",
    "        for i in range(hidden_size):\n",
    "            if i == 0:\n",
    "                model.add(LSTM(initial_num_unit, input_shape=(look_back, 1), return_sequences=return_sequences[i]))\n",
    "            else:\n",
    "                model.add(LSTM(initial_num_unit // 2**i, return_sequences=return_sequences[i]))\n",
    "        model.add(Dense(1))\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        if save:\n",
    "            return_sequences = [True] * (hidden_size - 1) + [False]\n",
    "            model = Sequential()\n",
    "            for i in range(hidden_size):\n",
    "                if i == 0:\n",
    "                    model.add(LSTM(initial_num_unit, input_shape=(look_back, 1), return_sequences=return_sequences[i]))\n",
    "                else:\n",
    "                    model.add(LSTM(initial_num_unit // 2**i, return_sequences=return_sequences[i]))\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "            model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "            \n",
    "            \n",
    "            sc = MinMaxScaler(feature_range=(0,1))\n",
    "            train_scaled = sc.fit_transform(X_train_temp)\n",
    "            test_scaled = sc.transform(X_test_temp)\n",
    "            val_scaled = sc.transform(X_val_temp)\n",
    "            \n",
    "            packager(train_scaled , val_scaled , test_scaled)\n",
    "            \n",
    "            \n",
    "            model.fit(X, y, epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            y_pred = model.predict(X_test)\n",
    "            org_y_pred = sc.inverse_transform(y_pred.reshape(-1,1))\n",
    "            org_y_test = sc.inverse_transform(y_test.reshape(-1,1))\n",
    "            \n",
    "            testScore = mean_absolute_percentage_error(org_y_test, org_y_pred)\n",
    "            \n",
    "            model.save(f'../models/lstm_model_{hidden_size}_{initial_num_unit}_{learning_rate}_{epoch}_{round(testScore, 4)}.h5')\n",
    "        else:\n",
    "            model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            return model\n",
    "        \n",
    "    elif unit_style == 'increase':\n",
    "        return_sequences = [True] * (hidden_size - 1) + [False]\n",
    "        model = Sequential()\n",
    "        for i in range(hidden_size):\n",
    "            if i == 0:\n",
    "                model.add(LSTM(initial_num_unit, input_shape=(look_back, 1), return_sequences=return_sequences[i]))\n",
    "            else:\n",
    "                model.add(LSTM(initial_num_unit * 2**i, return_sequences=return_sequences[i]))\n",
    "        model.add(Dense(1))\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        if save:\n",
    "            model.fit(X, y, epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            model.save(f'../models/lstm_model_{hidden_size}_{initial_num_unit}_{learning_rate}_{epoch}.h5')\n",
    "        else:\n",
    "            model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            return model\n",
    "        \n",
    "    elif unit_style == \"same\":\n",
    "        return_sequences = [True] * (hidden_size - 1) + [False]\n",
    "        model = Sequential()\n",
    "        for i in range(hidden_size):\n",
    "            if i == 0:\n",
    "                model.add(LSTM(initial_num_unit, input_shape=(look_back, 1), return_sequences=return_sequences[i]))\n",
    "            else:\n",
    "                model.add(LSTM(initial_num_unit, return_sequences=return_sequences[i]))\n",
    "        model.add(Dense(1))\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "        if save:\n",
    "            model.fit(X, y, epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            model.save(f'../models/lstm_model_{hidden_size}_{initial_num_unit}_{learning_rate}_{epoch}.h5')\n",
    "        else:\n",
    "            model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epoch, batch_size=batch_size, verbose=1)\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty lists to store model results\n",
    "hidden_sizes = []\n",
    "initial_units_list = []\n",
    "learning_rates_list = []\n",
    "epochs_list = []\n",
    "train_scores = []\n",
    "val_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "hidden_layer_sizes = [2,3,4,5]\n",
    "initial_num_units = [128,64,32,16]\n",
    "learning_rates = [0.001, 0.01]\n",
    "epochs = [5, 10, 20, 30]\n",
    "\n",
    "# Define the number of epochs and batch size to use in training\n",
    "batch_size = 1\n",
    "\n",
    "# Define the number of previous time steps to use as input features\n",
    "look_back = 24\n",
    "        \n",
    "        \n",
    "for hidden_size in hidden_layer_sizes:\n",
    "    for initial_num_unit in initial_num_units:\n",
    "        for learning_rate in learning_rates:\n",
    "            for epoch in epochs:\n",
    "                print(f\"Hidden size : {hidden_size} , Initial Num neurons : {initial_num_unit} , Learning Rate : {learning_rate} , Epoch : {epoch}\")\n",
    "                model = create_lstm_model(hidden_size, initial_num_unit, learning_rate , epoch = epoch , unit_style= 'decrease' )\n",
    "                \n",
    "                \n",
    "                trainPredict = model.predict(X_train)\n",
    "                valPredict = model.predict(X_val)\n",
    "                testPredict = model.predict(X_test)\n",
    "                org_y_train_pred = scaler.inverse_transform(trainPredict)\n",
    "                org_y_val_pred = scaler.inverse_transform(valPredict)\n",
    "                org_y_test_pred = scaler.inverse_transform(testPredict)\n",
    "                \n",
    "                org_y_train = scaler.inverse_transform(y_train.reshape(-1,1))\n",
    "                org_y_val = scaler.inverse_transform(y_val.reshape(-1,1))\n",
    "                org_y_test = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "                \n",
    "                trainScore = mean_absolute_percentage_error(org_y_train, org_y_train_pred)\n",
    "                valScore = mean_absolute_percentage_error(org_y_val, org_y_val_pred)\n",
    "                testScore = mean_absolute_percentage_error(org_y_test_pred, org_y_test_pred)\n",
    "\n",
    "\n",
    "                # Append results to lists\n",
    "                hidden_sizes.append(hidden_size)\n",
    "                initial_units_list.append(initial_num_unit)\n",
    "                learning_rates_list.append(learning_rate)\n",
    "                epochs_list.append(epoch)\n",
    "                train_scores.append(trainScore)\n",
    "                val_scores.append(valScore)\n",
    "                test_scores.append(testScore)\n",
    "                print(f\"Hidden size : {hidden_size} , Initial Num neurons : {initial_num_unit} , Learning Rate : {learning_rate} , Epoch : {epoch} , Unit Style : {'Decrease'} \")\n",
    "                print(f\"Train Score : {trainScore} , Val Score : {valScore} , Test Score : {testScore}\")\n",
    "                print(\"--------------------------------------------------------------------------------\")\n",
    "                if testScore < 0.02 :\n",
    "                    create_lstm_model(hidden_size , initial_num_unit , learning_rate , epoch = epoch, save= True)\n",
    "\n",
    "# Create dataframe from results\n",
    "results_df = pd.DataFrame({\n",
    "    'HiddenSize': hidden_sizes,\n",
    "    'Initial Num Neurons': initial_units_list,\n",
    "    'LearningRate': learning_rates_list,\n",
    "    'Epoch': epochs_list,\n",
    "    'TrainScore': train_scores,\n",
    "    'valScore': val_scores,\n",
    "    'TestScore': test_scores\n",
    "}).sort_values(by='TestScore' , ascending=False)\n",
    "\n",
    "# Print dataframe\n",
    "results_df.style.format(\"{:.2%}\").background_gradient(cmap=\"Blues\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataframe\n",
    "results_df.style.format(\"{:.2%}\").background_gradient(cmap=\"Blues\")\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test | Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
