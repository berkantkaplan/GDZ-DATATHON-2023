{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_initializer='glorot_uniform', bias_initializer='zeros', recurrent_activation='sigmoid', activation='tanh', dropout=0.2, recurrent_dropout=0.2, return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation='tanh', recurrent_activation='sigmoid', dropout=0.2, recurrent_dropout=0.2, kernel_initializer='glorot_uniform', bias_initializer='zeros', return_sequences=True))\n",
    "#     # model.add(LSTM(16 , activation=activation, recurrent_activation='sigmoid' , dropout=0, recurrent_dropout=0.1 , kernel_initializer=\"glorot_uniform\", bias_initializer='zeros' , return_sequences=False))\n",
    "#     model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128]}\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , grid_result.predict(X_test))}')\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_initializer='glorot_uniform', bias_initializer='zeros', recurrent_activation='sigmoid', activation='tanh', dropout=0.2, recurrent_dropout=0.2, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation='tanh', recurrent_activation='sigmoid', dropout=0.2, recurrent_dropout=0.2, kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "#     # model.add(LSTM(16 , activation=activation, recurrent_activation='sigmoid' , dropout=0, recurrent_dropout=0.1 , kernel_initializer=\"glorot_uniform\", bias_initializer='zeros' , return_sequences=False))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128]}\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , grid_result.predict(X_test))}')\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_initializer='glorot_uniform', bias_initializer='zeros', recurrent_activation='sigmoid', activation='tanh', dropout=0.2, recurrent_dropout=0.2, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation='tanh', recurrent_activation='sigmoid', dropout=0.2, recurrent_dropout=0.2, kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "#     # model.add(LSTM(16 , activation=activation, recurrent_activation='sigmoid' , dropout=0, recurrent_dropout=0.1 , kernel_initializer=\"glorot_uniform\", bias_initializer='zeros' , return_sequences=False))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     return model\n",
    "\n",
    "# model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128]}\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , grid_result.predict(X_test))}')\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from tensorflow.keras.losses import MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons, epochs):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_initializer='glorot_uniform', bias_initializer='zeros', recurrent_activation='sigmoid', activation='tanh', dropout=0.2, recurrent_dropout=0.2, return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation='tanh', recurrent_activation='sigmoid', dropout=0.2, recurrent_dropout=0.2, kernel_initializer='glorot_uniform', bias_initializer='zeros', return_sequences=True))\n",
    "#     model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "#     adam = Adam(lr = 0.001)\n",
    "#     model.compile(optimizer=adam, loss=MeanAbsolutePercentageError())\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'epochs': [10, 50, 100]}\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, std, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# import tensorflow as tf\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons, epochs):\n",
    "#     model = Sequential()\n",
    "#     with tf.device('/device:GPU:0'):\n",
    "#         model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_initializer='glorot_uniform', bias_initializer='zeros', recurrent_activation='sigmoid', activation='tanh', dropout=0.2, recurrent_dropout=0.2, return_sequences=True, seed=seed_value))\n",
    "#         for i in range(hidden_layers-1):\n",
    "#             model.add(LSTM(neurons, activation='tanh', recurrent_activation='sigmoid', dropout=0.2, recurrent_dropout=0.2, kernel_initializer='glorot_uniform', bias_initializer='zeros', return_sequences=True))\n",
    "#         model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "#         model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'epochs': [10, 50, 100]}\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, std, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from tensorflow.keras.losses import MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons, activation, epochs , learning_rate):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_initializer='glorot_uniform', bias_initializer='zeros', recurrent_activation='sigmoid', activation=activation, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation=activation, recurrent_activation='sigmoid', dropout=0.2, recurrent_dropout=0.2, kernel_initializer='glorot_uniform', bias_initializer='zeros', return_sequences=True))\n",
    "#     # model.add(LSTM(16 , activation=activation, recurrent_activation='sigmoid' , dropout=0, recurrent_dropout=0.1 , kernel_initializer=\"glorot_uniform\", bias_initializer='zeros' , return_sequences=False))\n",
    "#     model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "#     adam = Adam(lr = learning_rate)\n",
    "#     model.compile(optimizer=adam, loss=MeanAbsolutePercentageError())\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'activation': ['tanh', 'relu', 'sigmoid'],\n",
    "#               'epochs': [10, 50, 100],\n",
    "#               'learning_rate' : [0.001 , 0.005 , 0.003]}\n",
    "\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , grid_result.predict(X_test))}')\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons, activation, epochs):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_initializer='glorot_uniform', bias_initializer='zeros', recurrent_activation='sigmoid', activation=activation, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation=activation, recurrent_activation='sigmoid', dropout=0.2, recurrent_dropout=0.2, kernel_initializer='glorot_uniform', bias_initializer='zeros', return_sequences=True))\n",
    "#     # model.add(LSTM(16 , activation=activation, recurrent_activation='sigmoid' , dropout=0, recurrent_dropout=0.1 , kernel_initializer=\"glorot_uniform\", bias_initializer='zeros' , return_sequences=False))\n",
    "#     model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'activation': ['tanh', 'relu', 'sigmoid'],\n",
    "#               'epochs': [10, 50, 100]}\n",
    "\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , grid_result.predict(X_test))}')\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapsamlı GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from tensorflow.keras.losses import MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons, activation, epochs, validation_split , learning_rate):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_initializer='glorot_uniform', bias_initializer='zeros', recurrent_activation='tanh', activation=activation, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation=activation, recurrent_activation='tanh', dropout=0.2, recurrent_dropout=0.2, kernel_initializer='glorot_uniform', bias_initializer='zeros', return_sequences=True))\n",
    "#     # model.add(LSTM(16 , activation=activation, recurrent_activation='sigmoid' , dropout=0, recurrent_dropout=0.1 , kernel_initializer=\"glorot_uniform\", bias_initializer='zeros' , return_sequences=False))\n",
    "#     model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "#     adam = Adam(lr = learning_rate)\n",
    "#     model.compile(optimizer=adam, loss=MeanAbsolutePercentageError())\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'activation': ['tanh', 'relu'],\n",
    "#               'epochs': [10, 50, 100],\n",
    "#               'learning_rate' : [0.001 , 0.005 , 0.003]}\n",
    "\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid , cv = 1 , scoring= 'neg_mean_absolute_percentage_error')\n",
    "# grid_result = grid.fit(X_train, y_train , validation_data = (X_val , y_val))\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , grid_result.predict(X_test))}')\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ayarlanmış GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from tensorflow.keras.losses import MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons , epochs, validation_split , learning_rate):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_initializer='glorot_uniform', bias_initializer='zeros', recurrent_activation='tanh', activation='tanh', dropout=0.2, recurrent_dropout=0.2, return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation='tanh', recurrent_activation='tanh', dropout=0.2, recurrent_dropout=0.2, kernel_initializer='glorot_uniform', bias_initializer='zeros', return_sequences=True))\n",
    "#     # model.add(LSTM(16 , activation=activation, recurrent_activation='sigmoid' , dropout=0, recurrent_dropout=0.1 , kernel_initializer=\"glorot_uniform\", bias_initializer='zeros' , return_sequences=False))\n",
    "#     model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "#     adam = Adam(lr = learning_rate)\n",
    "#     model.compile(optimizer=adam, loss=MeanAbsolutePercentageError())\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'epochs': [10, 50, 100],\n",
    "#               'learning_rate' : [0.001 , 0.005 , 0.003]}\n",
    "\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid , cv = 1 , scoring= 'neg_mean_absolute_percentage_error')\n",
    "# grid_result = grid.fit(X_train, y_train , validation_data = (X_val , y_val))\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , grid_result.predict(X_test))}')\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapsamlı Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV , RandomizedSearchCV\n",
    "# from tensorflow.keras.losses import MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons, activation, epochs, validation_split , learning_rate):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_initializer='glorot_uniform', bias_initializer='zeros', recurrent_activation='tanh', activation=activation, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation=activation, recurrent_activation='tanh', dropout=0.2, recurrent_dropout=0.2, kernel_initializer='glorot_uniform', bias_initializer='zeros', return_sequences=True))\n",
    "#     # model.add(LSTM(16 , activation=activation, recurrent_activation='sigmoid' , dropout=0, recurrent_dropout=0.1 , kernel_initializer=\"glorot_uniform\", bias_initializer='zeros' , return_sequences=False))\n",
    "#     model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "#     adam = Adam(lr = learning_rate)\n",
    "#     model.compile(optimizer=adam, loss=MeanAbsolutePercentageError())\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'activation': ['tanh', 'relu'],\n",
    "#               'epochs': [10, 50, 100],\n",
    "#               'learning_rate' : [0.001 , 0.005 , 0.003]}\n",
    "\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=1, verbose=1, random_state=81, scoring='neg_mean_absolute_percentage_error')\n",
    "\n",
    "# random_result = random_search.fit(X_train, y_train, validation_data = (X_val , y_val))\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , random_result.predict(X_test))}')\n",
    "# print(f\"Best: {random_result.best_score_} using {random_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = random_result.cv_results_['mean_test_score']\n",
    "# stds = random_result.cv_results_['std_test_score']\n",
    "# params = random_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ayarlanmış RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed , Reshape\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV , RandomizedSearchCV\n",
    "# from tensorflow.keras.losses import MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# import numpy as np\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons, epochs, learning_rate):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), activation='tanh', return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation='tanh', return_sequences=True))\n",
    "#     model.add(LSTM(16, activation='tanh', return_sequences=True))\n",
    "#     model.add(TimeDistributed(Dense(16, activation='linear')))\n",
    "#     model.add(Reshape((-1, 1)))\n",
    "#     adam = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=adam, loss=MeanAbsolutePercentageError())\n",
    "#     return model\n",
    "\n",
    "# # X_train, y_train, X_val, y_val, X_test, y_test şeklinde verilerinizi tanımlayın\n",
    "\n",
    "# # Verileri birleştirin\n",
    "# X = np.concatenate((X_train, X_val), axis=0)\n",
    "# y = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'epochs': [10, 50, 100],\n",
    "#               'learning_rate': [0.001 , 0.005 , 0.003]}\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=2, verbose=1, random_state=81, scoring='neg_mean_absolute_percentage_error')\n",
    "\n",
    "# random_result = random_search.fit(X, y)\n",
    "\n",
    "# y_pred = random_result.predict(X_test)\n",
    "# y_pred = np.reshape(y_pred, (y_pred.shape[0], y_pred.shape[1]))\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , y_pred)}')\n",
    "# print(f\"Best: {random_result.best_score_} using {random_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = random_result.cv_results_['mean_test_score']\n",
    "# stds = random_result.cv_results_['std_test_score']\n",
    "# params = random_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed , Reshape\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV , RandomizedSearchCV\n",
    "# from tensorflow.keras.losses import MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons , learning_rate):\n",
    "#     model = Sequential()\n",
    "#     # model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_initializer='glorot_uniform' , bias_initializer='zeros', recurrent_activation='hard_sigmoid',dropout=0, activation='tanh', recurrent_dropout=0, return_sequences=True, seed=seed_value))\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), activation='tanh', return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         # model.add(LSTM(neurons, activation='tanh', recurrent_activation='tanh', kernel_initializer='glorot_uniform' , dropout=0.2, recurrent_dropout=0.2, bias_initializer='zeros', return_sequences=True))\n",
    "#         model.add(LSTM(neurons, activation='tanh', return_sequences=True))\n",
    "#     # model.add(LSTM(16 , activation='tanh', recurrent_activation='tanh' , kernel_initializer='glorot_uniform', dropout=0, recurrent_dropout=0.1 , bias_initializer='zeros' , return_sequences=False))\n",
    "#     model.add(LSTM(16 , activation='tanh' , return_sequences=False))\n",
    "#     model.add(Reshape((-1, 1))) # add this line to reshape the output of the TimeDistributed layer\n",
    "#     model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "#     adam = Adam(learning_rate = learning_rate)\n",
    "#     model.compile(optimizer=adam, loss=MeanAbsolutePercentageError())\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'epochs': [10, 50, 100],\n",
    "#               'learning_rate' : [0.001 , 0.005 , 0.003]}\n",
    "\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=2, verbose=1, random_state=81, scoring='neg_mean_absolute_percentage_error')\n",
    "\n",
    "# random_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , random_result.predict(X_test))}')\n",
    "# print(f\"Best: {random_result.best_score_} using {random_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = random_result.cv_results_['mean_test_score']\n",
    "# stds = random_result.cv_results_['std_test_score']\n",
    "# params = random_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed , Reshape\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV , RandomizedSearchCV\n",
    "# from tensorflow.keras.losses import MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons, epochs, learning_rate):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), activation='tanh', return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation='tanh', return_sequences=True))\n",
    "#     model.add(LSTM(16, activation='tanh', return_sequences=False))\n",
    "#     model.add(TimeDistributed(Dense(16, activation='linear')))\n",
    "#     model.add(Reshape((-1, 1)))\n",
    "#     adam = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=adam, loss=MeanAbsolutePercentageError())\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'epochs': [10, 50, 100],\n",
    "#               'learning_rate' : [0.001 , 0.005 , 0.003]}\n",
    "\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=2, verbose=1, random_state=81, scoring='neg_mean_absolute_percentage_error')\n",
    "\n",
    "# random_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , random_result.predict(X_test))}')\n",
    "# print(f\"Best: {random_result.best_score_} using {random_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = random_result.cv_results_['mean_test_score']\n",
    "# stds = random_result.cv_results_['std_test_score']\n",
    "# params = random_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed , Reshape\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV , RandomizedSearchCV\n",
    "# from tensorflow.keras.losses import MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# def create_model(seed_value, hidden_layers, neurons, epochs , learning_rate):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), activation='tanh', return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation='tanh', return_sequences=True))\n",
    "#     model.add(LSTM(16, activation='tanh', return_sequences=False))\n",
    "#     model.add(TimeDistributed(Dense(16, activation='linear')))\n",
    "#     model.add(Reshape((-1, 1)))\n",
    "#     adam = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=adam, loss=MeanAbsolutePercentageError())\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# param_grid = {'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'epochs': [10, 50, 100],\n",
    "#               'learning_rate' : [0.001 , 0.005 , 0.003]}\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=2, verbose=1, random_state=81, scoring='neg_mean_absolute_percentage_error')\n",
    "\n",
    "# random_result = random_search.fit(X_train, y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , random_result.predict(X_test))}')\n",
    "# print(f\"Best: {random_result.best_score_} using {random_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = random_result.cv_results_['mean_test_score']\n",
    "# stds = random_result.cv_results_['std_test_score']\n",
    "# params = random_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed , Reshape\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV , RandomizedSearchCV\n",
    "# from tensorflow.keras.losses import MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# import numpy as np\n",
    "\n",
    "# def create_model(X_train, y_train, X_val, y_val, seed_value, hidden_layers, neurons, epochs, learning_rate):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]), activation='tanh', return_sequences=True, seed=seed_value))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation='tanh', return_sequences=True))\n",
    "#     model.add(LSTM(16, activation='tanh', return_sequences=True))\n",
    "#     model.add(TimeDistributed(Dense(16, activation='linear')))\n",
    "#     model.add(Reshape((-1, 1)))\n",
    "#     adam = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=adam, loss=MeanAbsolutePercentageError())\n",
    "#     history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0)\n",
    "#     return history, model\n",
    "\n",
    "\n",
    "# # X_train, y_train, X_val, y_val, X_test, y_test şeklinde verilerinizi tanımlayın\n",
    "\n",
    "# # Verileri birleştirin\n",
    "# X = np.concatenate((X_train, X_val), axis=0)\n",
    "# y = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "\n",
    "# param_grid = {'X_train': [X_train], \n",
    "#               'y_train': [y_train],\n",
    "#               'X_val': [X_val],\n",
    "#               'y_val': [y_val],\n",
    "#               'seed_value': [0, 1, 2],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'neurons': [32, 64, 128],\n",
    "#               'epochs': [10, 50, 100],\n",
    "#               'learning_rate': [0.001 , 0.005 , 0.003]}\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=2, verbose=1, random_state=81, scoring='neg_mean_absolute_percentage_error')\n",
    "\n",
    "# random_result = random_search.fit(X, y)\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , random_result.predict(X_test))}')\n",
    "# print(f\"Best: {random_result.best_score_} using {random_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = random_result.cv_results_['mean_test_score']\n",
    "# stds = random_result.cv_results_['std_test_score']\n",
    "# params = random_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize edilmiş farklı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, LSTM, TimeDistributed , Reshape\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV , RandomizedSearchCV\n",
    "# from tensorflow.keras.losses import MeanAbsolutePercentageError\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# import numpy as np\n",
    "\n",
    "# def create_model(neurons, hidden_layers, X_shape):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(neurons, input_shape=(X_shape[1], X_shape[2]), activation='tanh', return_sequences=True))\n",
    "#     for i in range(hidden_layers-1):\n",
    "#         model.add(LSTM(neurons, activation='tanh', return_sequences=True))\n",
    "#     model.add(LSTM(16, activation='tanh', return_sequences=True))\n",
    "#     model.add(TimeDistributed(Dense(16, activation='linear')))\n",
    "#     model.add(Reshape((-1, 1)))\n",
    "#     adam = Adam()\n",
    "#     model.compile(optimizer=adam, loss=MeanAbsolutePercentageError())\n",
    "#     return model\n",
    "\n",
    "# # X_train, y_train, X_val, y_val, X_test, y_test şeklinde verilerinizi tanımlayın\n",
    "\n",
    "# # Verileri birleştirin\n",
    "# X = np.concatenate((X_train, X_val), axis=0)\n",
    "# y = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "\n",
    "# # Modeli önceden eğitelim\n",
    "# trained_model = create_model(neurons=32, hidden_layers=2, X_shape=X_train.shape)\n",
    "# history = trained_model.fit(X, y, epochs=50, verbose=0)\n",
    "\n",
    "# param_grid = {'neurons': [32, 64, 128],\n",
    "#               'hidden_layers': [1, 2, 3],\n",
    "#               'learning_rate': [0.001 , 0.005 , 0.003]}\n",
    "\n",
    "# random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=2, verbose=1, random_state=81, scoring='neg_mean_absolute_percentage_error')\n",
    "\n",
    "# random_result = random_search.fit(X, y)\n",
    "\n",
    "# print(f'Our Eval Metric TEST : {eval_metrics(y_test , random_result.predict(X_test))}')\n",
    "# print(f\"Best: {random_result.best_score_} using {random_result.best_params_}\")\n",
    "# print(\"All Results:\")\n",
    "# means = random_result.cv_results_['mean_test_score']\n",
    "# stds = random_result.cv_results_['std_test_score']\n",
    "# params = random_result.cv_results_['params']\n",
    "# for mean, std, param in zip(means, stds, params):\n",
    "#     print(f\"{mean} {std} with: {param}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a generator function to load data in batches\n",
    "# def batch_generator(data, look_back, batch_size):\n",
    "#     num_batches = len(data) // batch_size\n",
    "#     for i in range(num_batches):\n",
    "#         start_idx = i * batch_size\n",
    "#         end_idx = start_idx + batch_size\n",
    "#         batch = data[start_idx:end_idx]\n",
    "#         x_batch = np.zeros((batch_size, look_back, 1))\n",
    "#         y_batch = np.zeros((batch_size, 1))\n",
    "#         for j in range(batch_size):\n",
    "#             x_batch[j] = batch[j:j+look_back]\n",
    "#             y_batch[j] = batch[j+look_back]\n",
    "#         yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
